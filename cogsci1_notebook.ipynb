{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Cog Sci 1] 7 Plus-or-Minus 2 Billion: Human Brains vs. Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professor Paul Li "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Estimated Time: 50 Minutes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/brain-data-image.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Covered \n",
    "Welcome! This lab will be an introduction to Big Data and the Human Brain as well as a gentle introduction to Jupyter Notebooks. By the end of this lab you will be able to: \n",
    "1. Define _Big Data_ and _dimensions_ in reference to a data set\n",
    "2. Explain the high-level steps of simple computer facial recognition\n",
    "3. Identify 3 reasons related to human cognition limits that we reduce the dimensions of big data during analysis\n",
    "4. Identify 2 human ethics limitations/consequences that can result from reducing the dimensions of a large data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "1. [Jupyter Notebooks](#section 1)\n",
    "   - [Running Cells](#section 1.1)\n",
    "   - [The Data](#section 1.2)\n",
    "   - [Context](#section 1.3)\n",
    "<br/><br/>\n",
    "2. [Big Data](#section 2) \n",
    "   - [What is Big Data?](#section 2.1) \n",
    "   - [Dimensionality](#section 2.2)\n",
    "<br/><br/>\n",
    "3. [Computer Vision: Recognizing Faces In An Image](#section 3)\n",
    "   - [Overview of Facial Recognition](#section 3.1)\n",
    "   - [Ethics of Facial Recognition](#section 3.2) \n",
    "   - [How Do These Systems Work?](#section 3.3)\n",
    "   - [How Do Humans Recognize Faces?](#section 3.4)\n",
    "<br/><br/>\n",
    "4. [Dimensionality Reduction](#section 4)\n",
    "<br/><br/>\n",
    "5. [Big Data Can Be Too Big!](#section 5)\n",
    "   - [Why Would We Simplify Data? ](#section 5.1)\n",
    "   - [What Are The Risks With Simplifying Data?](#section 5.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cogsci88.png\", width=700, height=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Jupyter Notebook is an online, interactive computing environment, composed of different types of __cells__. Cells are chunks of code or text that are used to break up a larger notebook into smaller, more manageable parts and to let the viewer modify and interact with the elements of the notebook.\n",
    "\n",
    "Notice that the notebook consists of 2 different kinds of cells: **markdown** and **code**. A markdown cell (like this one) contains text, while a code cell contains expressions in Python, the programming language in this Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/python_logo.png\", width=200, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Cells <a id='section 1.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Running\" a cell is similar to pressing 'Enter' on a calculator once you've typed in an expression; it computes all of the expressions contained within the cell.\n",
    "\n",
    "To run a code cell, you can do one of the following:\n",
    "- press __Shift + Enter__\n",
    "- click __Cell -> Run Cells__ in the toolbar at the top of the screen.\n",
    "\n",
    "You can navigate the cells by either clicking on them or by using your up and down arrow keys. Try running the cell below to see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of the cell consists of the text/code that is contained within the cell's enclosing box. Here, the input is an expression in Python that \"prints\" or repeats whatever text or number is passed in. \n",
    "\n",
    "The output of running a cell is shown in the line immediately after it. Notice that markdown cells have no output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data <a id='section 1.2'></a>\n",
    "\n",
    "In this lab we will be using the Olivetti faces dataset that contains a set of face images that were captured between April 1992 and April 1994 at AT&T Laboratories Cambridge. There are 10 different images of 40 distinct subjects. The images were not taken in the same lighting conditions, time of day, and the subjects did not all have the same facial expressions. All of the images, however, were taken against a dark background with the subejcts facing the camera. It is important to note that no efforts were made to create a diversified unbiased population sample. The images in this dataset do not represent the wider population of the US at the time, so any algorithm that was fed this data would not be able to be extrapolated to apply to the rest of the country. The participants were not chosen randomly.Some example pictures are in the cell below. Check out this [link](<https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html>) for more information!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/olivetti_faces.png\", width=450, height=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context <a id='section 1.3'></a>\n",
    "\n",
    "This lab explores how cognitive limits encourage different techniques to simplifying information, such as computer programs breaking down data into different parts. This is similar to how the nervous system breaks down infomration that it receives from the environment. Our brains and _Big Data_ algorithms need to simplify the mass amounts of data they receive in order to efficiently process it and output a result. You will learn about simple facial recognition and how this relates to how the brain process images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/big_data.png\", width=800, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is _Big Data_? <a id='section 2.1'></a>\n",
    "The term _Big Data_ seems to be a buzz word everywhere lately, but what really is _Big Data_? _Big Data_ refers to an extremely large data set that may be analyzed to reveal patterns, trends, associations, especially relating to human behavior. Most companies and organizations collect data on every transaction or interaction for each user or consumer, so the data can expand very quickly! \n",
    "\n",
    "Consider the image data that your brain deals with, we are constantly processing information from our eyes which expands with every passing second. This adds up to a lot of data to PROCESS. While the dataset that we will be using later in this notebook, is not this big, it is still important to recognize that _Big Data_ is everywhere. Both computer programs and our brains deal with large amount of data every day, and have developed strategies of efficiently processing this information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality <a id='section 2.2'></a>\n",
    "\n",
    "How is the size of a dataset measured? Dimensionality refers to how many attributes a dataset has. For example, if Berkeley had a dataset of students with each row representing a students, some variables could be: residency, year, major, units, gpa, etc. A high dimensional dataset means that the number of dimensions are very large and that calculations could become difficult and the number of features can exceed the number of observations. Later in this lab, you will learn about how reducing the dimensionality of your data can affect an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision: Recogizing Faces In An Image <a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/computer_vision.png\", width=500, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Facial Recognition <a id='section 3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facial Recognition systems are computer programs that analyze images of human faces in order to identify the individuals present in them. These systems can be used for general surveillance in a public setting with public video cameras, for personal security purposes, and in many other situations. An well known example of facial recognition is the Face ID feature of an iPhone X. The phone only unlocks when you either enter a passcord, or if it recognizes your face. In general, these systems work by comparing selected facial features from a given image, to faces that are already known within a databse. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/facial_recognition.png\", width=500, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethics of Facial Recognition <a id='section 3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to recognize that these systems are not correct, and the mistakes they make can be devastating to certain groups. Two well publicized controversies include Hewlett-Packard's face-tracking web camera and Google's facial recognition software for their Photos application. \n",
    "\n",
    "Desi Cryer, an African American man, uploaded a video in 2009 to YouTube showing that the face-tracking web camera did not track his face, while it had no problems following his white colleague. In a separate instance, Google's Photos application labeled some African American people as \"gorillas.\" Part of the problem with these facial recognition systems is that their data that they use to train their algorithms is flawed. A common dataset used to train these systems is more than 75% male and more than 80% white, which could produce the results of the algorithm classifying minorities in this dataset incorrectly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/facial_rec_new.png\", width=400, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Do These Systems Work? <a id='section 3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facial recognition systems use computer algorithms to pick out distinctive features and details of a person's face. The computer looks for the ways that faces can be different such as the distance between eyes, shading on the face and many other features. Below are the steps of how common algorithms work: \n",
    "\n",
    "1. Image is captured\n",
    "2. Eye locations are determined\n",
    "3. Image is converted to grayscale and cropped\n",
    "4. Image is converted ot a template used by the program for facial comparison reults\n",
    "5. Image is searched and matched using an algorithm to compare the template to other templates on file \n",
    "\n",
    "source: https://www.eff.org/pages/face-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/facial_rec_steps.png\", width=350, height=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Do Humans Recognize Faces? <a id='section 3.4'></a>\n",
    "\n",
    "Our ability to recognize faces quickly and efficently is remarkable. But, how do we actually do it? Your brain can identify items and faces within milliseconds and is a complex process.\n",
    "\n",
    "\n",
    "In early face recognition processing, the occipital lobe recognizes individual features of a face, such as the eyes, ears, nose etc. Then, the fusiform gyrus, an area of the brain that is involved when you look at a face, is activated. It is responsible for holistic information, meaning it puts all of the information from the occipital lobe together for further processing. Then, this whole face is compared to previous faces that we've seen, and the determination of recognition is completed. Humans recognize faces as a 'sum of parts' while a computer recognizes the parts of a face, and if enough match, then determines the corresponding face. In computer vision, everything is an amalgam of components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.brainblogger.com/2015/10/17/how-the-brain-recognizes-faces/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction <a id='section 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, we need to run the following cell to import packages that will be used later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages that will be used later\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the data into the notebook. Again, you don't have to know how the code is implemented, but think of it as \"opening\" the data like you would open an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run to load the data\n",
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset of facial images with a high number of dimensions, it can be very taxing for a computer to work with this data. Often, a process used to counter this issue is dimensionality reduction. When working with big data, we can perform an analysis where we look at the dimensions and order them in terms of significance to the dataset, and then we can reduce the number of dimensions by removing the less important ones.\n",
    "\n",
    "This process is in fact finding the principal components of the data. The first few principal components are the most important components in determining the underlying structure of the data. In terms of a dataset containing images of faces, the first components are the most important in determining the overall appearance of the face. The first few components are associated with the lighting conditions on the face, and later components deal with certain features like eyes, noses, lips, etc.\n",
    "\n",
    "Using this analysis, we can add and subtract different components until we get a good enough approximation of the data. By figuring out which components have the greatest importance, we are able to remove the less important components and in effect greatly reduce the size of the data we're working with while maintaining a close resemblance to the original data.\n",
    "\n",
    "We can perform dimensionality reduction on the Olivetti faces dataset that we loaded. Each image is of size 64 x 64 pixels, and as a result the dimensionality is over 4,000. However, through this analysis we can easily reduce to 400 components and get approximations that are practically indistinguishable from the original images, and we can reduce by even more and still get close approximations. To see this analysis in action, run the following cells below. With the widget, play with adding and subtracting the number of components to see how the accuracy changes. Try to see at what point do the faces become unrecognizable with their original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb68cf8bc72482e9dcc2ad35eeb5626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dimensionality_reduction(x):\n",
    "    pca = decomposition.PCA(n_components=x)\n",
    "    pca.fit(faces.data)\n",
    "    components = pca.transform(faces.data)\n",
    "    projected = pca.inverse_transform(components)\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    for i in range(10):\n",
    "        ax = fig.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(projected[10*i].reshape(faces.images[10*i].shape), cmap=plt.cm.bone)\n",
    "\n",
    "interact(dimensionality_reduction,\n",
    "         x=widgets.IntSlider(min=1, max=400, step=1, value=200,\n",
    "                             description='Number of Components:',\n",
    "                             style={'description_width':'initial'},\n",
    "                             layout=widgets.Layout(width='75%'),\n",
    "                             continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Can Be Too Big! <a id='section 5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Would We Simplify Data? <a id='section 5.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove noise\n",
    "- speed up computation\n",
    "- make analysis more likely to be human understandable \n",
    "- tie in article: “can users control and understand a UI driven by machine learning?” (Spoiler: no, and they want to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before, one of the reasons we would perform dimensionality reduction on big data is to speed up computation. Keep in mind, when talking about an extremely large dataset, we're dealing with possibly billions to trillions of records of data. Any reduction or simplification of the data would positively affect processing and computing speed. Of course, it is also dependent on the machine doing the computation &mdash; a supercomputer will have much more computational power to work with big data.\n",
    "\n",
    "Another reason we would want to simplify data is to remove any noise from the dataset. Noise is essentially meaningless information contained within a dataset, such as corrupted or distorted data, and noise often arrives through the data collection process. Ideally, we would want to remove any noisy data as it can negatively affect the results of any analysis.\n",
    "\n",
    "Lastly, simplifying data allows us to make any analysis more likely to be understandable to humans. Often when "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Are The Risks With Simplifying Data? <a id='section 5.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Can potentially connect to lots of real-life examples:\n",
    "- Takeaway: if we simplify data sets to account for “most” variation, algorithms trained on that data can then fail to work well for edge cases. In real life, “edge cases” often are minorities/people underrepresented in data\n",
    "- Google Images tags dark-skinned people as “gorillas”\n",
    "- HP cameras only recognize light-skinned faces\n",
    "- NY Times on history of facial recognition controversy\n",
    "- perhaps changing the data inputs the data scientist's bias into the dataset \n",
    "\n",
    "\n",
    "\n",
    "- https://www.eff.org/pages/face-recognition\n",
    "- good article for downsides of facial recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography \n",
    "\n",
    "https://www.nngroup.com/articles/machine-learning-ux/?utm_medium=email&utm_source=topic+optin&utm_campaign=awareness&utm_content=20181219_data_nl&mkt_tok=eyJpIjoiWXpFME5tWXlabU5sTlRKbCIsInQiOiJudk40bEs0ZU4xOWwrblpabEQzUGRpS1pJbEFkMXcyTUgxd2VBclMxRWt2TW5MZVdRczZLNlp6XC9CbHJITlwvVlwvYThXd0swckRMbTFNXC9CVDJ4cEQyY0ZLM29OWDlkNjJaRmhOVDNFcVR0NFpTVXEyTXc3RFUySDczU1dESCtWbGoifQ%3D%3D\n",
    "\n",
    "- https://scikit-learn.org/0.19/datasets/olivetti_faces.html\n",
    "- https://scikit-learn.org/0.19/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces\n",
    "- https://scikit-learn.org/0.19/auto_examples/plot_multioutput_face_completion.html#sphx-glr-auto-examples-plot-multioutput-face-completion-py\n",
    "- https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_eigenfaces.html\n",
    "- https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb\n",
    "- https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/\n",
    "- https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6\n",
    "- https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Custom.html\n",
    "- https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html\n",
    "- https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Styling.html\n",
    "\n",
    "image 1: https://clalliance.org/blog/computing-brains-neuroscience-machine-intelligence-and-big-data-in-the-cognitive-classroom/\n",
    "\n",
    "image 2: https://www.reply.com/en/topics/big-data-and-analytics/a-harmonised-big-data-management-model \n",
    "\n",
    "image 3: https://www.wollybi.com/en/2018/03/05/big-data-analytics-opportunities-in-the-digital-era/\n",
    "\n",
    "image 4: http://data8.org/connector/Cognitive%20Science/ \n",
    "\n",
    "image 5: http://terminalcoders.blogspot.com/2017/03/at-face-database-in-png.html\n",
    "\n",
    "image 6: https://www.weareworldquant.com/en/thought-leadership/understanding-images-computer-vision-in-flux/\n",
    "\n",
    "image 7: https://medium.com/wobot-intelligence/how-facial-recognition-is-the-next-big-disruption-e3d4ac73666f\n",
    "\n",
    "image 8: https://www.eff.org/pages/face-recognition \n",
    "\n",
    "\n",
    "https://pixabay.com/images/search/computer%20science/\n",
    "\n",
    "https://pixabay.com/illustrations/flat-recognition-facial-face-woman-3252983/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Notebook developed by: Maria Sooklaris, Joshua Asuncion\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
